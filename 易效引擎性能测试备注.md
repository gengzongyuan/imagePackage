---
title: 易效引擎性能测试备注
tags: 性能测试 ,易效,引擎,工作
renderNumberedHeading: true
grammar_cjkRuby: true
---

#### 影响因素
##### 业务db--->NDC--->kafka
- 业务DB  binlog写
- NDC 运维侧是否用同一套处理逻辑，是否会对不同的环境采用不同的engine
- kafka规模

##### 埋点数据收集
- AOP将节点数据放到redis或者消息队列中,外部redis或者消息队列的性能会对测试情况有影响


#### 整体链路
##### 测试点1:KAFKA -> 实时系统
```
	实时读kafka数据
	实时转化
	实时往kafka写数据
```

##### 测试点2:实时系统 -> us
```
	us消费kafka数据
	us处理kafka数据
	us更新内存数据
```
##### 测试范围
- 由于设计订阅字段的增删改，需要确定本次涉及的范围
	- 从订阅表里圈定一部分还是进行全量测试
- 针对测试范围订阅表的增删改数据变动，需要进行评估数据量的多少才是合适的
	- 评估方式1：参照业务接口并发情况，估算（注意未来三年）
	- 评估方式2：通过线上日志（binlog）进行汇总处理，确定详细数据量，并在这个数据量上预估未来三年
```
订阅表名、字段清单（只传输订阅字段）：
1）user_info：id, account_status, price, reward_price, budget, industry_level_1_id, industry_level_2_id, has_deeplink
2）ad_convert：id, status, feedback_url
3）ad_plan：id, status, turn, budget, creater, cast_speed, start_date, end_date, ask_type
4）ad_plan_askdate：id, day, hours, ad_plan_id
5）scheduling_info：id, ad_plan_id, creater, status, turn, cast_way, system, pay, network, sex, age, device_price, network_operator, app_type, device, sub_platform, type_direction, ad_formats
6）scheduling_dp_interest：id, scheduling_info_id, interest_code, level
7）scheduling_dp_person：id, scheduling_id, type, person_package_id
8）scheduling_dp_areas：id, scheduling_info_id, area_code
9）scheduling_category_package：id, scheduling_id, category_package_id
10）category_package_item：id, category_package_id, category_id
11）scheduling_position_package：id, scheduling_id, position_package_id
12）position_package_item：id, position_package_id, position_id
13）idea_info：id, title, descript, status, turn, idea_type, scheduling_info_id, create_time, update_time, name, source, direct_url, android_url, ios_url, close_ad_interact, doc_id, ext_type, btn_type, telephone, has_form_name, has_form_phone,deeplink
14）idea_material_mapping：id, idea_info_id, material_info_id, position_num
15）material_info：id, url, material_size, material_type,processed_url
16）blacklist_info：id, platform, request_param, user_id, status
17）ad_position：id, type, parent_id, channel_id, column_code, location, position, ad_type, cpc_floor_price, cpm_floor_price
18）ad_display：id, access_service_id, style, code
19）ad_access_service：id, position_id, code
20 ) idea_convert : id, idea_id, convert_id
```
```
订阅表名、字段清单（只传输订阅字段）：
1）ad_channel_shielding_words：id, channel_id, name
2）ad_position_black_white_list：id, position_id, dsp_advertiser_ids, type, data_status
3）ad_industry_blacklist：id, position_id, column_id, industry_id
```


##### 实现方式
```
通过埋点的形式将信息（时间戳、处理状态、测试类型、当前事件id）放到中转处
写脚本实现对中转数据的汇总===>考虑是否做成实时的


这里有两种方案：
1:logstash--->kafka--->写demo对kafka数据进行实时处理
2:程序将数据输出到kafka或者redis中---->写demo对数据进行处理
```


##### 测试场景
###### 基准
```


```

###### 并发
- 数据规模：见上方细节测试点部分
```

```

```


```

###### 综合
```
测试点1+测试点2同步执行，看两块的影响
```

###### 稳定性
```
- 测试点1+测试点2整条链路的稳定性
```

##### 监控指标
- 机器指标
```
走哨兵看就可以
```
- 时间指标
```
见实现方式，具体时间节点待定

tps
avg
50%
90%
```
- 其他指标
```
失败率
```
- 负载均衡指标
```
增加埋点里的信息数据，看是哪台consumer消费的数据
```
![测试](https://raw.githubusercontent.com/gengzongyuan/imagePackage/master/imagePackage/1575011306474.png)
- JVM监控
```
这里看现在引擎对cat的使用如何，能是直接使用cat进行监控
内存泄露
GC抖动
现有的垃圾回收机制是否需要优化
```

##### 相关信息
- 测试kafka
```
chuanmei-k8s0.jd.163.org:9092,chuanmei-k8s1.jd.163.org:9092,chuanmei-k8s2.jd.163.org:9092,chuanmei-k8s3.jd.163.org:9092 
```

- trans
```
topic：test_topic_yx_business_data_for_realtime_adqa_pre
订阅组：test_yx_qa

topic：test_topic_yunguan_business_data_for_realtime_adqa_pre
topic副本数：2
订阅组：test_yunguan_qa
```

- us
```
消费topic:ad_model_data_transform_from_db_for_engine_topic_pre
```
